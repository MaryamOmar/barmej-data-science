{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 10 \n",
    "\n",
    "first task is already done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Task \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request,jsonify\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "import psycopg2\n",
    "\n",
    "# init app\n",
    "app = Flask(__name__)\n",
    "\n",
    "engine = db.create_engine(\"postgresql+psycopg2://{user}:{pw}@localhost/{db}\"\n",
    "                       .format(user=\"postgres\",\n",
    "                               pw=\"mypass\",\n",
    "                               db=\"test\"))\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "Base = declarative_base()\n",
    "metadata = db.MetaData()\n",
    "label_types = db.Table('label_types', metadata, autoload=True, autoload_with=engine)\n",
    "data_labeling = db.Table('data_labeling', metadata, autoload=True, autoload_with=engine)\n",
    "data_input = db.Table('data_input', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"hello!\"\n",
    "\n",
    "\n",
    "@app.route('/get_total_data_count/<name>', methods=['GET'])\n",
    "def get_total_data_count(name):\n",
    "\n",
    "    try:\n",
    "        sem_num= session.query(data_labeling,label_types\n",
    "                                  ).join(label_types, data_labeling.c.label_id == label_types.c.label_id\n",
    "                                         ).filter(label_types.c.label_name==name\n",
    "                                                  ).count()\n",
    "        if (name == 'all'):\n",
    "                sem_num= session.query(data_labeling,label_types\n",
    "                                          ).join(label_types,data_labeling.c.label_id == label_types.c.label_id).count()\n",
    "\n",
    "        return jsonify(sem_num)\n",
    "\n",
    "    except:\n",
    "        return \"Please use one of the following options: positive, negative, all .\"\n",
    "\n",
    "\n",
    "@app.route('/get_data/<int:max_count>/<int:page>/<sort_order>', methods=['GET'])\n",
    "def get_data(max_count,page,sort_order):\n",
    "    try:\n",
    "        if(sort_order == 'desc'):\n",
    "            sort_order = 'data_input.c.input_date.desc()'\n",
    "        elif(sort_order == 'asc'):\n",
    "            sort_order = 'data_input.c.input_date.asc()'\n",
    "\n",
    "        recordes = session.query(data_input.c.input,data_labeling.c.label_id\n",
    "                                ).join(data_input,data_labeling.c.input_id == data_input.c.id\n",
    "                                      ).order_by(eval(sort_order)\n",
    "                                                ).offset(page).limit(max_count).all()\n",
    "\n",
    "        return jsonify(recordes)\n",
    "\n",
    "    except  Exception as e:\n",
    "        return \"Error in rout\" + str(e)\n",
    "\n",
    "\n",
    "# run server\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, port=3000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Task \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "command : ssh ubuntu@ip-172-31-12-170 'python3 an.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    y.append(text[1]) #get labels.\n",
    "    text= str(text[0]) #get input.\n",
    "    text = text.lower() #lower case.\n",
    "    text = re.sub('\\S*@\\S*\\s?', '',text)  # remove emails.\n",
    "    text = re.sub('[^a-z \\n ]+', '',text) #remove everything but letters.\n",
    "    text = re.sub('\\n', ' ',text) #remove new line char and replace it with a space.\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text) #remove singl chars.\n",
    "    return text\n",
    "\n",
    "\n",
    "size =requests.get('http://127.0.0.1:3000/get_total_data_count/all').json()\n",
    "data = []\n",
    "resp = requests.get('http://127.0.0.1:3000/get_data/15/0/asc')\n",
    "if resp:\n",
    "    print('Success!')\n",
    "    print('the size of the data set = ',size)\n",
    "    data.extend(resp.json())                                                                                                                                                                                           max= 15                                                                                                                                                                                                            page=15                                                                                                                                                                                                            while len(data) < size:\n",
    "        resp = requests.get('http://127.0.0.1:3000/get_data/{max}/{page}/asc'.format(max=max,page=page))\n",
    "        data.extend(resp.json())\n",
    "        page=page+max\n",
    "else:\n",
    "    print('Not Found.')\n",
    "\n",
    "with open('model.pickle', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "with open('vectorizer.pickle', 'rb') as file:\n",
    "    vectorizer = pickle.load(file)\n",
    "\n",
    "y =[]\n",
    "\n",
    "for i in  range(len(data)):                                                                                                                                                                                            data[i]= clean_text(data[i])\n",
    "\n",
    "\n",
    "test_vector = vectorizer.transform(data)\n",
    "result = model.predict(test_vector)\n",
    "print(\"calss of:\", data[0])\n",
    "print(result[0])\n",
    "\n",
    "print('model accuracy=', accuracy_score(y, result))\n",
    "neg= (result== 0).sum()\n",
    "pos= (result== 1).sum()\n",
    "\n",
    "negative_count=size =requests.get('http://127.0.0.1:3000/get_total_data_count/negative').json()\n",
    "positive_count=requests.get('http://127.0.0.1:3000/get_total_data_count/positive').json()\n",
    "print('negative data in the database: ', negative_count , ' in prediction: ',neg )\n",
    "print('positive data in the database: ', positive_count, ' in prediction: ',pos )\n",
    "\n",
    "with open('forestmdl.pickle', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "with open('cv.pickle', 'rb') as file:\n",
    "    vectorizer = pickle.load(file)\n",
    "    \n",
    "test_vector = vectorizer.transform(data)\n",
    "result = model.predict(test_vector)\n",
    "\n",
    "print('random forest model accuracy=', accuracy_score(y, result))\n",
    "pos= (result== 1).sum()\n",
    "neg= (result== 0).sum()\n",
    "print('negative data in the database: ', negative_count , ' in prediction: ',neg )                                                                                                                                 print('positive data in the database: ', positive_count, ' in prediction: ',pos )                                                                                                                                                                                                                                                                                                                                                     \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "استعملت المودل المرفق في المشروع، واستعملت مودل اخر تم تدريبه على مراجعات امازون: \n",
    "![Image of output](https://i.imgur.com/WiCGpPI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Task \n",
    "\n",
    "video link: https://drive.google.com/file/d/1K8veXadU1GxtkWZaREA_Po6XaUW8_9Kn/view?usp=sharing\n",
    "قطعت الاتصال اختصاراً للوقت \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
